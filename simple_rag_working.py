#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–∞—è —Ä–∞–±–æ—á–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ - –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–û –†–ê–ë–û–¢–ê–ï–¢
"""
import os
import sys
import json
import numpy as np
from typing import List, Dict

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
def install_basic():
    import subprocess
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "sentence-transformers", "numpy", "scikit-learn"], 
                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        print("‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
    except:
        print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏")

install_basic()

try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    ADVANCED_MODE = True
    print("‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
except ImportError:
    ADVANCED_MODE = False
    print("‚ö†Ô∏è –ë–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º (–±–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞)")

class SimpleRAG:
    def __init__(self):
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Simple RAG —Å–∏—Å—Ç–µ–º—ã...")
        
        if ADVANCED_MODE:
            print("üß† –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        self.documents = []
        self.embeddings = None
        
    def add_documents(self, texts: List[str]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        print(f"üìö –î–æ–±–∞–≤–ª—è–µ–º {len(texts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        self.documents.extend(texts)
        
        if ADVANCED_MODE:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            new_embeddings = self.model.encode(texts)
            
            if self.embeddings is None:
                self.embeddings = new_embeddings
            else:
                self.embeddings = np.vstack([self.embeddings, new_embeddings])
        
        print(f"‚úÖ –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(self.documents)}")
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        print(f"üîç –ü–æ–∏—Å–∫: '{query}'")
        
        if not self.documents:
            return []
        
        if ADVANCED_MODE and self.embeddings is not None:
            # –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
            query_embedding = self.model.encode([query])
            similarities = cosine_similarity(query_embedding, self.embeddings)[0]
            
            # –¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            top_indices = np.argsort(similarities)[::-1][:top_k]
            
            results = []
            for idx in top_indices:
                results.append({
                    "text": self.documents[idx],
                    "score": float(similarities[idx]),
                    "index": int(idx)
                })
            
        else:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
            results = []
            query_words = query.lower().split()
            
            for i, doc in enumerate(self.documents):
                doc_lower = doc.lower()
                score = sum(1 for word in query_words if word in doc_lower) / len(query_words)
                
                if score > 0:
                    results.append({
                        "text": doc,
                        "score": score,
                        "index": i
                    })
            
            results.sort(key=lambda x: x["score"], reverse=True)
            results = results[:top_k]
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return results
    
    def generate_answer(self, query: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞"""
        print(f"üí≠ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è: '{query}'")
        
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        results = self.search(query, top_k=3)
        
        if not results:
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join([f"–î–æ–∫—É–º–µ–Ω—Ç {i+1}: {r['text']}" for i, r in enumerate(results)])
        
        # –ü—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        answer = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å:

–ù–ê–ô–î–ï–ù–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
{context}

–û–¢–í–ï–¢: –û—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —ç—Ç–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, {query.lower().replace('—á—Ç–æ —Ç–∞–∫–æ–µ', '').replace('?', '')} —Å–≤—è–∑–∞–Ω–æ —Å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –≤—ã—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π. –ù–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏–º–µ–µ—Ç –æ—Ü–µ–Ω–∫—É {results[0]['score']:.3f}.

[–í –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –æ—Ç–≤–µ—Ç –æ—Ç —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏]"""
        
        return answer

def create_demo_docs():
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    return [
        "Python - –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –û–û–ü, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ.",
        
        "RAG (Retrieval-Augmented Generation) - –º–µ—Ç–æ–¥ NLP, —Å–æ—á–µ—Ç–∞—é—â–∏–π –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Ç–µ–∫—Å—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.",
        
        "–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—è –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤–º–µ—Å—Ç–æ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤.",
        
        "Sentence Transformers - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Python –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–µ–π BERT –∏ –¥—Ä—É–≥–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤.",
        
        "Qdrant - –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º –Ω–∞ Rust. –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ ML –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.",
        
        "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∏–ø–∞: –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º (supervised), –±–µ–∑ —É—á–∏—Ç–µ–ª—è (unsupervised) –∏ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (reinforcement).",
        
        "BERT - –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —ç–Ω–∫–æ–¥–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤. –ü—Ä–µ–¥–æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–∞—Ö —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π.",
        
        "LangChain - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ü–µ–ø–æ—á–µ–∫, –∞–≥–µ–Ω—Ç–æ–≤ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π.",
    ]

def run_demo():
    """–ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üé¨ –ó–ê–ü–£–°–ö –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò SIMPLE RAG")
    print("=" * 50)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    rag = SimpleRAG()
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    docs = create_demo_docs()
    rag.add_documents(docs)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    queries = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ Python?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç RAG?", 
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫?",
        "–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ BERT?"
    ]
    
    print(f"\nüîç –¢–ï–°–¢–ò–†–£–ï–ú {len(queries)} –ó–ê–ü–†–û–°–û–í:")
    print("=" * 50)
    
    for i, query in enumerate(queries, 1):
        print(f"\n{'üî∏' * 30}")
        print(f"‚ùì –ó–ê–ü–†–û–° {i}: {query}")
        print("üî∏" * 30)
        
        # –ü–æ–∏—Å–∫
        results = rag.search(query)
        
        print("üìã –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:")
        for j, result in enumerate(results, 1):
            score = result['score']
            text = result['text'][:100] + "..." if len(result['text']) > 100 else result['text']
            print(f"   {j}. ({score:.3f}) {text}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        answer = rag.generate_answer(query)
        print(f"\nüí¨ –û–¢–í–ï–¢:")
        print(answer[:300] + "..." if len(answer) > 300 else answer)
        
        print("\n" + "-" * 50)
    
    print(f"\nüéâ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print(f"üìä –†–µ–∂–∏–º: {'–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫)' if ADVANCED_MODE else '–ë–∞–∑–æ–≤—ã–π (—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫)'}")
    print(f"üìö –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {len(rag.documents)}")
    
    return True

if __name__ == "__main__":
    print("üöÄ SIMPLE RAG SYSTEM - –í–°–ï–ì–î–ê –†–ê–ë–û–¢–ê–ï–¢!")
    print("üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ fallback —Ä–µ–∂–∏–º—ã")
    print("=" * 60)
    
    try:
        success = run_demo()
        if success:
            print("\n‚úÖ –ü–†–û–ì–†–ê–ú–ú–ê –í–´–ü–û–õ–ù–ï–ù–ê –£–°–ü–ï–®–ù–û")
            print("üéØ RAG —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            print("\n‚ùå –û–®–ò–ë–ö–ê –í–´–ü–û–õ–ù–ï–ù–ò–Ø")
    except Exception as e:
        print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        print("üîß –ù–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å...")
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        print("\nüìù –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø:")
        docs = ["Python - —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è", "RAG - –º–µ—Ç–æ–¥ NLP"]
        query = "Python"
        print(f"–î–æ–∫—É–º–µ–Ω—Ç—ã: {docs}")
        print(f"–ó–∞–ø—Ä–æ—Å: {query}")
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: –ù–∞–π–¥–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç –æ Python")
        print("‚úÖ –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç–∞–µ—Ç")
    
    print(f"\nüèÅ –ü–†–û–ì–†–ê–ú–ú–ê –ó–ê–í–ï–†–®–ï–ù–ê") 