 #!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–æ–ª–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ —Å Qdrant
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é
"""

import os
import sys
import subprocess
import time
import logging
import uuid
import json
import pickle
from typing import List, Dict, Optional

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def install_package(package_name):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
    try:
        __import__(package_name.split('==')[0].replace('-', '_'))
        logger.info(f"‚úÖ {package_name} —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return True
    except ImportError:
        logger.info(f"üîß –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º {package_name}...")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", package_name, "-q"])
            logger.info(f"‚úÖ {package_name} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return True
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ {package_name}: {e}")
            return False

def install_dependencies():
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    logger.info("üöÄ –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏...")
    
    required_packages = [
        "numpy",
        "torch",
        "sentence-transformers",
        "qdrant-client",
        "requests"
    ]
    
    for package in required_packages:
        if not install_package(package):
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å {package}")
            return False
    
    logger.info("‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
    return True

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
if not install_dependencies():
    logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
    sys.exit(1)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
import requests

try:
    from qdrant_client import QdrantClient
    from qdrant_client.models import Distance, VectorParams, PointStruct
    from qdrant_client.http import models
    QDRANT_AVAILABLE = True
except ImportError:
    logger.warning("‚ö†Ô∏è Qdrant client –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
    QDRANT_AVAILABLE = False


class LocalVectorStore:
    """–õ–æ–∫–∞–ª—å–Ω–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∫–∞–∫ fallback –¥–ª—è Qdrant"""
    
    def __init__(self, storage_path="vector_storage"):
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
        
        self.vectors_file = os.path.join(storage_path, "vectors.npy")
        self.metadata_file = os.path.join(storage_path, "metadata.json")
        
        self.vectors = []
        self.metadata = []
        self.load_data()
    
    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        try:
            if os.path.exists(self.vectors_file):
                self.vectors = np.load(self.vectors_file).tolist()
            if os.path.exists(self.metadata_file):
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
            logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.vectors)} –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            self.vectors = []
            self.metadata = []
    
    def save_data(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª—ã"""
        try:
            if self.vectors:
                np.save(self.vectors_file, np.array(self.vectors))
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def add_vectors(self, vectors, metadata):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤"""
        self.vectors.extend(vectors)
        self.metadata.extend(metadata)
        self.save_data()
    
    def search(self, query_vector, top_k=5):
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤"""
        if not self.vectors:
            return []
        
        vectors_array = np.array(self.vectors)
        query_array = np.array(query_vector)
        
        # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = np.dot(vectors_array, query_array) / (
            np.linalg.norm(vectors_array, axis=1) * np.linalg.norm(query_array)
        )
        
        # –¢–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            results.append({
                "score": float(similarities[idx]),
                "metadata": self.metadata[idx],
                "index": int(idx)
            })
        
        return results


class SmartRAGSystem:
    """–£–º–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
    
    def __init__(self):
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Smart RAG —Å–∏—Å—Ç–µ–º—ã...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self._init_embedding_model()
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant
        self.qdrant_client = None
        self.use_qdrant = self._try_connect_qdrant()
        
        if not self.use_qdrant:
            logger.info("üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
            self.local_store = LocalVectorStore()
        
        self.collection_name = "smart_rag_documents"
    
    def _init_embedding_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        logger.info("üß† –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        logger.info(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)
        self.vector_size = self.embedding_model.get_sentence_embedding_dimension()
        
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {self.vector_size}")
    
    def _try_connect_qdrant(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant"""
        if not QDRANT_AVAILABLE:
            return False
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ Qdrant
            response = requests.get("http://localhost:6333/health", timeout=2)
            if response.status_code == 200:
                self.qdrant_client = QdrantClient(host="localhost", port=6333)
                self._create_qdrant_collection()
                logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Qdrant")
                return True
        except:
            pass
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—å Qdrant —á–µ—Ä–µ–∑ Docker
        try:
            logger.info("üê≥ –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å Qdrant —á–µ—Ä–µ–∑ Docker...")
            subprocess.run([
                "docker", "run", "-d", "--name", "qdrant_smart_rag", 
                "-p", "6333:6333", "qdrant/qdrant"
            ], check=True, capture_output=True)
            
            time.sleep(5)  # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞
            
            response = requests.get("http://localhost:6333/health", timeout=5)
            if response.status_code == 200:
                self.qdrant_client = QdrantClient(host="localhost", port=6333)
                self._create_qdrant_collection()
                logger.info("‚úÖ Qdrant –∑–∞–ø—É—â–µ–Ω –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω")
                return True
        except:
            pass
        
        logger.warning("‚ö†Ô∏è Qdrant –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
        return False
    
    def _create_qdrant_collection(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant"""
        try:
            collections = self.qdrant_client.get_collections()
            collection_exists = any(col.name == self.collection_name for col in collections.collections)
            
            if not collection_exists:
                self.qdrant_client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(size=self.vector_size, distance=Distance.COSINE)
                )
                logger.info(f"üì¶ –ö–æ–ª–ª–µ–∫—Ü–∏—è '{self.collection_name}' —Å–æ–∑–¥–∞–Ω–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
    
    def add_documents(self, texts: List[str], metadata: List[Dict] = None) -> bool:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        if not texts:
            return False
        
        if metadata is None:
            metadata = [{"index": i, "text_preview": text[:100]} for i, text in enumerate(texts)]
        
        logger.info(f"üìö –î–æ–±–∞–≤–ª—è–µ–º {len(texts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embeddings = self.embedding_model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)
        
        if self.use_qdrant:
            return self._add_to_qdrant(texts, embeddings, metadata)
        else:
            return self._add_to_local(texts, embeddings, metadata)
    
    def _add_to_qdrant(self, texts, embeddings, metadata):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ Qdrant"""
        try:
            points = []
            for text, emb, meta in zip(texts, embeddings, metadata):
                point = PointStruct(
                    id=str(uuid.uuid4()),
                    vector=emb.tolist(),
                    payload={"text": text, "metadata": meta}
                )
                points.append(point)
            
            self.qdrant_client.upsert(collection_name=self.collection_name, points=points)
            logger.info(f"‚úÖ {len(points)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ Qdrant")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ Qdrant: {e}")
            return False
    
    def _add_to_local(self, texts, embeddings, metadata):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        try:
            local_metadata = []
            for text, meta in zip(texts, metadata):
                local_metadata.append({
                    "text": text,
                    "metadata": meta,
                    "id": str(uuid.uuid4())
                })
            
            self.local_store.add_vectors(embeddings.tolist(), local_metadata)
            logger.info(f"‚úÖ {len(texts)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {e}")
            return False
    
    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        logger.info(f"üîç –ü–æ–∏—Å–∫: '{query}'")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embedding_model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]
        
        if self.use_qdrant:
            return self._search_qdrant(query_embedding, top_k)
        else:
            return self._search_local(query_embedding, top_k)
    
    def _search_qdrant(self, query_embedding, top_k):
        """–ü–æ–∏—Å–∫ –≤ Qdrant"""
        try:
            search_result = self.qdrant_client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding.tolist(),
                limit=top_k,
                with_payload=True
            )
            
            results = []
            for hit in search_result:
                results.append({
                    "id": hit.id,
                    "score": hit.score,
                    "text": hit.payload.get("text", ""),
                    "metadata": hit.payload.get("metadata", {})
                })
            
            return results
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Qdrant: {e}")
            return []
    
    def _search_local(self, query_embedding, top_k):
        """–ü–æ–∏—Å–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
        try:
            search_results = self.local_store.search(query_embedding, top_k)
            
            results = []
            for result in search_results:
                meta = result["metadata"]
                results.append({
                    "id": meta.get("id", "unknown"),
                    "score": result["score"],
                    "text": meta.get("text", ""),
                    "metadata": meta.get("metadata", {})
                })
            
            return results
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {e}")
            return []
    
    def generate_rag_response(self, query: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è RAG –æ—Ç–≤–µ—Ç–∞"""
        # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        search_results = self.search(query, top_k=3)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_parts = []
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"–î–æ–∫—É–º–µ–Ω—Ç {i} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['score']:.3f}):\n{result['text']}")
        
        context = "\n\n".join(context_parts)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        prompt = f"""–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–û–ù–¢–ï–ö–°–¢:
{context}

–í–û–ü–†–û–°: {query}

–û–¢–í–ï–¢: –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, """
        
        return {
            "query": query,
            "context": context,
            "prompt": prompt,
            "search_results": search_results,
            "storage_type": "Qdrant" if self.use_qdrant else "–õ–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"
        }
    
    def get_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
        if self.use_qdrant:
            try:
                info = self.qdrant_client.get_collection(self.collection_name)
                return {
                    "storage_type": "Qdrant",
                    "documents_count": info.points_count,
                    "vectors_count": info.vectors_count,
                    "status": info.status
                }
            except:
                return {"storage_type": "Qdrant", "status": "error"}
        else:
            return {
                "storage_type": "–õ–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ",
                "documents_count": len(self.local_store.metadata),
                "vectors_count": len(self.local_store.vectors),
                "status": "active"
            }


def create_sample_documents():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    return [
        "Python - –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –û–û–ü, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ. –ò–º–µ–µ—Ç –ø—Ä–æ—Å—Ç–æ–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –∏ –æ–±—à–∏—Ä–Ω—É—é —ç–∫–æ—Å–∏—Å—Ç–µ–º—É –±–∏–±–ª–∏–æ—Ç–µ–∫.",
        
        "Qdrant - —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ø–∏—Å–∞–Ω–Ω–∞—è –Ω–∞ Rust. –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ ML –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è.",
        
        "RAG (Retrieval-Augmented Generation) - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, —Å–æ—á–µ—Ç–∞—é—â–∞—è –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Ç–µ–∫—Å—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM.",
        
        "BERT - –º–æ–¥–µ–ª—å –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –∏ –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç–∞.",
        
        "Sentence Transformers - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –û—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ BERT –∏ –¥—Ä—É–≥–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞—Ö. –ü–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–∫—Å—Ç—ã.",
        
        "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤–∫–ª—é—á–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º (supervised), –±–µ–∑ —É—á–∏—Ç–µ–ª—è (unsupervised) –∏ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (reinforcement). –ö–∞–∂–¥—ã–π —Ç–∏–ø —Ä–µ—à–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∑–∞–¥–∞—á.",
        
        "–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º, —Ç–∞–∫ –∫–∞–∫ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –∏ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞—Ö.",
        
        "LangChain - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Å —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ø–æ—á–µ–∫, –∞–≥–µ–Ω—Ç–æ–≤ –∏ —Å–ª–æ–∂–Ω—ã—Ö workflow —Å LLM."
    ]


def run_demonstration():
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    logger.info("üé¨ === –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø SMART RAG –°–ò–°–¢–ï–ú–´ ===")
    logger.info("=" * 60)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
        rag_system = SmartRAGSystem()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã
        stats = rag_system.get_stats()
        logger.info(f"üìä –¢–∏–ø —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {stats['storage_type']}")
        logger.info(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats.get('documents_count', 0)}")
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        sample_docs = create_sample_documents()
        metadata = [
            {"topic": "programming", "language": "python"},
            {"topic": "database", "type": "vector"},
            {"topic": "ai", "method": "rag"},
            {"topic": "ai", "model": "bert"},
            {"topic": "ml", "library": "sentence-transformers"},
            {"topic": "ai", "type": "learning"},
            {"topic": "search", "method": "vector"},
            {"topic": "framework", "type": "langchain"}
        ]
        
        success = rag_system.add_documents(sample_docs, metadata)
        if not success:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã")
            return False
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        test_queries = [
            "–ß—Ç–æ —Ç–∞–∫–æ–µ Python –∏ –µ–≥–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏?",
            "–û–±—ä—è—Å–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã RAG",
            "–ö–∞–∫–∏–µ —Ç–∏–ø—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—Ç?",
            "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫?",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ BERT –∏ –∫–∞–∫ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è?"
        ]
        
        logger.info(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(test_queries)} –∑–∞–ø—Ä–æ—Å–æ–≤...")
        
        for i, query in enumerate(test_queries, 1):
            logger.info(f"\n{'='*80}")
            logger.info(f"‚ùì –ó–∞–ø—Ä–æ—Å {i}/{len(test_queries)}: {query}")
            logger.info("-" * 80)
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ RAG –∑–∞–ø—Ä–æ—Å–∞
            response = rag_system.generate_rag_response(query)
            
            logger.info(f"üè™ –•—Ä–∞–Ω–∏–ª–∏—â–µ: {response['storage_type']}")
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(response['search_results'])}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for j, result in enumerate(response['search_results'][:2], 1):
                text_preview = result['text'][:120] + "..." if len(result['text']) > 120 else result['text']
                logger.info(f"  {j}. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['score']:.3f}")
                logger.info(f"     {text_preview}")
            
            # –ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç
            prompt_preview = response['prompt'][:200] + "..." if len(response['prompt']) > 200 else response['prompt']
            logger.info(f"üí≠ –ü—Ä–æ–º–ø—Ç (–Ω–∞—á–∞–ª–æ): {prompt_preview}")
            
            time.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        final_stats = rag_system.get_stats()
        logger.info(f"\nüìä === –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===")
        logger.info(f"üè™ –¢–∏–ø —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {final_stats['storage_type']}")
        logger.info(f"üìÑ –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {final_stats.get('documents_count', 0)}")
        logger.info(f"üî¢ –í–µ–∫—Ç–æ—Ä–æ–≤: {final_stats.get('vectors_count', 0)}")
        logger.info(f"‚ö° –°—Ç–∞—Ç—É—Å: {final_stats.get('status', 'unknown')}")
        
        logger.info(f"\nüéâ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if rag_system.use_qdrant:
            logger.info("üåê Qdrant dashboard: http://localhost:6333/dashboard")
        else:
            logger.info("üìÅ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: vector_storage/")
        
        logger.info("üí° –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        logger.exception("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")
        return False


if __name__ == "__main__":
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Smart RAG System")
    
    success = run_demonstration()
    
    if success:
        logger.info("‚úÖ –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    else:
        logger.error("‚ùå –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
        sys.exit(1)